{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abSETEd/check_phone/blob/main/checkphone_verwww.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Versão 1 finalizada"
      ],
      "metadata": {
        "id": "eBwdQEE5OnI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala as dependências necessárias\n",
        "!pip install beautifulsoup4\n",
        "!pip install openpyxl\n",
        "!pip install requests\n",
        "!pip install pandas\n",
        "!pip install pyexcel-ods3\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import openpyxl  # Para XLSX\n",
        "from google.colab import files  # Para o upload no Colab\n",
        "import io  # Para processar o arquivo enviado\n",
        "import re  # Para expressões regulares\n",
        "import os  # Pra manipular nomes de arquivo\n",
        "import pyexcel_ods3\n",
        "\n",
        "# Função para carregar a planilha em diferentes formatos\n",
        "def carregar_planilha(arquivo_carregado, nome_arquivo):\n",
        "    try:\n",
        "        if nome_arquivo.endswith('.csv'):\n",
        "            df = pd.read_csv(io.BytesIO(arquivo_carregado))\n",
        "        elif nome_arquivo.endswith('.xlsx'):\n",
        "            df = pd.read_excel(io.BytesIO(arquivo_carregado), engine='openpyxl')\n",
        "        elif nome_arquivo.endswith('.ods'):\n",
        "            ods_data = pyexcel_ods3.get_data(io.BytesIO(arquivo_carregado))\n",
        "            df = pd.DataFrame(ods_data[list(ods_data.keys())[0]][1:], columns=ods_data[list(ods_data.keys())[0]][0])\n",
        "        else:\n",
        "            raise ValueError(\"Formato de arquivo não suportado. Use CSV, XLSX ou ODS.\")\n",
        "\n",
        "        colunas_esperadas = [\"Site\", \"qtd CNPJs\", \"qtd UF MVX\", \"CNPJ\", \"CNPJRaiz\", \"RazaoSocial\", \"Logradouro\",\n",
        "                            \"Numero2\", \"Complemento\", \"Bairro\", \"Cidade\", \"Uf\", \"Cep\", \"CapitalSocial\",\n",
        "                            \"Cnae\", \"CodigoPredio\", \"Predio\", \"NaturezaJuridica\", \"DescNaturezaJuridica\",\n",
        "                            \"Mailing\", \"SDR\"]\n",
        "\n",
        "        colunas_faltantes = [col for col in colunas_esperadas if col not in df.columns]\n",
        "        if colunas_faltantes:\n",
        "          raise ValueError(f\"As colunas {colunas_faltantes} não foram encontradas na planilha\")\n",
        "\n",
        "        if 'Site' not in df.columns:\n",
        "          raise ValueError(\"A planilha precisa ter uma coluna chamada 'Site'.\")\n",
        "\n",
        "        # Formata a coluna 'Site' adicionando 'https://' se necessário\n",
        "        df['Site'] = df['Site'].apply(lambda x: f\"https://www.{x}\" if not str(x).startswith(('http://', 'https://')) else x)\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar a planilha: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para consultar um site e extrair telefones\n",
        "def consultar_site(url):\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        resposta = requests.get(url, headers=headers, timeout=10)\n",
        "        resposta.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(resposta.text, 'html.parser')\n",
        "        texto = soup.get_text()\n",
        "\n",
        "        # Padrão flexível pra telefones no Brasil\n",
        "        padrao_telefone = r'(?:(?:\\+?55\\s?)?(?:\\(?\\d{2}\\)?)?\\s?\\d{4,5}[-.\\s]?\\d{4})'\n",
        "        telefones = re.findall(padrao_telefone, texto)\n",
        "        telefones_unicos = list(set(telefones))\n",
        "\n",
        "        if telefones_unicos:\n",
        "            return ', '.join(telefones_unicos)  # Junta os telefones com vírgula\n",
        "        else:\n",
        "            return \"Nenhum telefone encontrado\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Erro ao acessar {url}: {e}\")\n",
        "        return \"Erro na consulta\"\n",
        "\n",
        "# Função principal\n",
        "def main():\n",
        "    print(\"Por favor, faça o upload da sua planilha (CSV, XLSX ou ODS):\")\n",
        "\n",
        "    # Interface de upload\n",
        "    uploaded = files.upload()  # Abre o seletor de arquivos\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"Nenhum arquivo foi enviado. Encerrando.\")\n",
        "        return\n",
        "\n",
        "    # Pega o nome e conteúdo do arquivo enviado\n",
        "    nome_arquivo = list(uploaded.keys())[0]\n",
        "    arquivo_carregado = uploaded[nome_arquivo]\n",
        "\n",
        "    # Carrega a planilha e formata URLs\n",
        "    df_urls = carregar_planilha(arquivo_carregado, nome_arquivo)\n",
        "    if df_urls is None:\n",
        "        return\n",
        "\n",
        "    print(f\"Carreguei {len(df_urls)} linhas da planilha: {nome_arquivo}\")\n",
        "\n",
        "    telefones = []\n",
        "    for index, row in df_urls.iterrows():\n",
        "        url = row['Site']\n",
        "        print(f\"Consultando: {url}\")\n",
        "\n",
        "        telefone = consultar_site(url)\n",
        "        telefones.append(telefone)\n",
        "        print(f\"Telefones para {url}: {telefone}\")\n",
        "\n",
        "        time.sleep(2)\n",
        "\n",
        "    df_urls['Telefone'] = telefones\n",
        "\n",
        "    colunas_antes = df_urls.columns[:df_urls.columns.get_loc('RazaoSocial') + 1].tolist()\n",
        "    colunas_depois = df_urls.columns[df_urls.columns.get_loc('Logradouro'):].tolist()\n",
        "    novas_colunas = colunas_antes + ['Telefone'] + colunas_depois\n",
        "\n",
        "    df_urls = df_urls[novas_colunas]\n",
        "\n",
        "    while True:\n",
        "      formato = input(\"Escolha o formto de saída (csv, xlsx, ods): \").lower().strip()\n",
        "      if formato in ['csv', 'xlsx', 'ods']:\n",
        "        break\n",
        "      print(\"Formato invalido! escolha entre 'csv', 'xlsx' ou 'ods'. \" )\n",
        "\n",
        "    nome_base = os.path.splitext(nome_arquivo)[0]\n",
        "    if formato == 'csv':\n",
        "        arquivo_saida = f\"{nome_base}_com_telefones.csv\"\n",
        "        df_urls.to_csv(arquivo_saida, index=False)\n",
        "        print(f'Arquivo salvo como {arquivo_saida} com {len(df_urls)} entradas.')\n",
        "        files.download(arquivo_saida)\n",
        "        print(f\" Baixe a planilha aqui {arquivo_saida}\")\n",
        "    elif formato == 'xlsx':\n",
        "        arquivo_saida = f\"{nome_base}_com_telefone.xlsx\"\n",
        "        df_urls.to_excel(arquivo_saida, index=False, engine='openpyxl')\n",
        "        print(f'Arquivo salvo como {arquivo_saida} com {len(df_urls)} entradas.')\n",
        "        files.download(arquivo_saida)\n",
        "        print(f\" Baixe a planilha aqui: {arquivo_saida}\")\n",
        "    elif formato == 'ods':\n",
        "        arquivo_saida = f\"{nome_base}_com_telefones.ods\"\n",
        "        df_urls = df_urls.fillna('')\n",
        "        pyexcel_ods3.save_data(arquivo_saida, {'Sheet1': [df_urls.columns.tolist()] + df_urls.values.tolist()})\n",
        "        print(f'Arquio salvo como {arquivo_saida} com {len(df_urls)} entradas.')\n",
        "        files.download(arquivo_saida)\n",
        "        print(f\" Baixe a planilha aqui: {arquivo_saida}\")\n",
        "\n",
        "# Executa o programa\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "XVxMP3GgOxt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Documentação\n",
        "\n",
        "O codigo, em medi, consegue pesquisar 1/3 dos sites.\n",
        "\n",
        "Ao verificar e validar alguns pontos pesquisando as urls que o codigo não conseguiu verificar e trazer o telefone percebi que:\n",
        "\n",
        "\n",
        "1.   sites que o telefone fica em outra pagina o bs4 nao consegue buscar, tenho que encontrar outras formas de pesquisa ou utilisar selenium\n",
        "2.   algumas paginas tem proteção contra web scraping que nao permite a execução do codigo.\n",
        "3.  Percebi também que numeros com 0800 não são trazidos pelo codigo.\n",
        "4. adicionei um www na pesquisa.\n",
        "- ao analisar a planilha e começar a prospectar apos passar ela pelo codigo, verifiquei que alguns sites precisavam ter www. antes para a pesquisa ser efetiva.\n"
      ],
      "metadata": {
        "id": "7lIO9kk2O6m8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# versão 2.\n",
        "*fase de teste*"
      ],
      "metadata": {
        "id": "sE72m5FFFlX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalações de bibliotecas Python\n",
        "!pip install beautifulsoup4\n",
        "!pip install openpyxl\n",
        "!pip install pyexcel-ods3\n",
        "!pip install tldextract\n",
        "\n",
        "# Importações\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import openpyxl  # Para XLSX\n",
        "from google.colab import files  # Para o upload no Colab\n",
        "import io  # Para processar o arquivo enviado\n",
        "import re  # Para expressões regulares\n",
        "import os  # Para manipular nomes de arquivo\n",
        "import pyexcel_ods3  # Para ler e salvar em ODS\n",
        "import tldextract\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Função para carregar a planilha em diferentes formatos\n",
        "def carregador_planilha(arquivo_carregado, nome_arquivo):\n",
        "    try:\n",
        "        if nome_arquivo.endswith('.csv'):\n",
        "            df = pd.read_csv(io.BytesIO(arquivo_carregado))\n",
        "        elif nome_arquivo.endswith('.xlsx'):\n",
        "            df = pd.read_excel(io.BytesIO(arquivo_carregado), engine='openpyxl')\n",
        "        elif nome_arquivo.endswith('.ods'):\n",
        "            ods_data = pyexcel_ods3.get_data(io.BytesIO(arquivo_carregado))\n",
        "            df = pd.DataFrame(ods_data[list(ods_data.keys())[0]][1:], columns=ods_data[list(ods_data.keys())[0]][0])\n",
        "        else:\n",
        "            raise ValueError(\"Formato de arquivo não suportado. Use CSV, XLSX ou ODS.\")\n",
        "\n",
        "        colunas_esperadas = [\"Site\", \"qtd CNPJs\", \"qtd UF MVX\", \"CNPJ\", \"CNPJRaiz\", \"RazaoSocial\", \"Logradouro\",\n",
        "                            \"Numero\", \"Complemento\", \"Bairro\", \"Cidade\", \"Uf\", \"Cep\", \"CapitalSocial\",\n",
        "                            \"Cnae\", \"CodigoPredio\", \"NaturezaJuridica\", \"DescNaturezaJuridica\",\n",
        "                            \"Mailing\", \"SDR\"]  # \"Data\" já foi removida anteriormente\n",
        "\n",
        "        colunas_faltantes = [col for col in colunas_esperadas if col not in df.columns]\n",
        "        if colunas_faltantes:\n",
        "            raise ValueError(f\"As colunas {colunas_faltantes} não foram encontradas na planilha.\")\n",
        "\n",
        "        if 'Site' not in df.columns:\n",
        "            raise ValueError(\"A planilha precisa ter uma coluna chamada 'Site'.\")\n",
        "\n",
        "        # Função para verificar se a URL é válida\n",
        "        def verificar_url(url):\n",
        "            try:\n",
        "                # Remove espaços\n",
        "                url = url.strip().replace(' ', '')\n",
        "\n",
        "                # Verifica pontos consecutivos\n",
        "                if re.search(r'\\.\\.+', url):\n",
        "                    return False\n",
        "\n",
        "                # Verifica caracteres inválidos\n",
        "                if not re.match(r'^[a-zA-Z0-9\\.\\-]+$', url):\n",
        "                    return False\n",
        "\n",
        "                # Extrai o domínio com tldextract\n",
        "                extracted = tldextract.extract(url)\n",
        "                if not extracted.domain or not extracted.suffix:  # Linha corrigida\n",
        "                    return False  # URL inválida (sem domínio ou TLD)\n",
        "\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao verificar URL {url}: {e}\")\n",
        "                return False\n",
        "\n",
        "        # Função para normalizar URLs válidas\n",
        "        def normalizar_url(url):\n",
        "            try:\n",
        "                # Remove espaços e caracteres inválidos\n",
        "                url = url.strip().replace(' ', '')\n",
        "                url = re.sub(r'[^a-zA-Z0-9\\.\\-]', '', url)\n",
        "\n",
        "                # Remove pontos consecutivos\n",
        "                url = re.sub(r'\\.+', '.', url)\n",
        "\n",
        "                # Extrai o domínio com tldextract\n",
        "                extracted = tldextract.extract(url)\n",
        "                if not extracted.domain or not extracted.suffix:\n",
        "                    return url  # Retorna a URL original se não puder normalizar\n",
        "\n",
        "                # Reconstrói o domínio (ex.: \"exemplo.com\")\n",
        "                dominio = f\"{extracted.domain}.{extracted.suffix}\"\n",
        "\n",
        "                # Adiciona o prefixo https://www.\n",
        "                return f\"https://www.{dominio}\"\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao normalizar URL {url}: {e}\")\n",
        "                return url\n",
        "\n",
        "        # Adiciona uma coluna para marcar URLs válidas\n",
        "        df['URL_Valida'] = df['Site'].apply(verificar_url)\n",
        "\n",
        "        # Normaliza apenas URLs válidas\n",
        "        df['Site'] = df.apply(lambda row: normalizar_url(row['Site']) if row['URL_Valida'] else row['Site'], axis=1)\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar a planilha: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função para consultar o site e extrair telefones com bs4\n",
        "def consultar_site(url):\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        resposta = requests.get(url, headers=headers, timeout=10)\n",
        "        resposta.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(resposta.text, 'html.parser')\n",
        "        texto = soup.get_text()\n",
        "\n",
        "        padrao_telefone = r'(?:(?:\\+?55\\s?)?(?:\\(?\\d{2}\\)?)?\\s?\\d{4,5}[-.\\s]?\\d{4})'\n",
        "        telefones = re.findall(padrao_telefone, texto)\n",
        "        telefones_unicos = list(set(telefones))\n",
        "\n",
        "        if telefones_unicos:\n",
        "            return ', '.join(telefones_unicos)\n",
        "        else:\n",
        "            return \"Nenhum telefone encontrado\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Erro ao acessar {url}: {e}\")\n",
        "        return \"Erro na consulta\"\n",
        "\n",
        "# Função principal\n",
        "def main():\n",
        "    print(\"Por favor, faça o upload da sua planilha (CSV, XLSX ou ODS):\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"Nenhum arquivo foi enviado. Encerrando.\")\n",
        "        return\n",
        "\n",
        "    nome_arquivo = list(uploaded.keys())[0]\n",
        "    arquivo_carregado = uploaded[nome_arquivo]\n",
        "\n",
        "    df_urls = carregador_planilha(arquivo_carregado, nome_arquivo)\n",
        "    if df_urls is None:\n",
        "        return\n",
        "\n",
        "    print(f\"Carreguei {len(df_urls)} linhas da planilha: {nome_arquivo}\")\n",
        "    print(f\"Total de URLs válidas para consulta: {df_urls['URL_Valida'].sum()}\")\n",
        "\n",
        "    telefones = []\n",
        "    for index, row in df_urls.iterrows():\n",
        "        url = row['Site']\n",
        "        if row['URL_Valida']:\n",
        "            print(f\"Consultando: {url}\")\n",
        "            telefone = consultar_site(url)\n",
        "            print(f\"Telefones para {url}: {telefone}\")\n",
        "        else:\n",
        "            print(f\"URL inválida, pulando consulta: {url}\")\n",
        "            telefone = \"URL inválida\"\n",
        "        telefones.append(telefone)\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Primeiro, adiciona a coluna 'Telefone' ao DataFrame original\n",
        "    df_urls['Telefone'] = telefones\n",
        "\n",
        "    # Depois, reorganiza as colunas para inserir 'Telefone' e 'URL_Valida' entre 'RazaoSocial' e 'Logradouro'\n",
        "    colunas_antes = df_urls.columns[:df_urls.columns.get_loc('RazaoSocial') + 1].tolist()\n",
        "    colunas_depois = df_urls.columns[df_urls.columns.get_loc('Logradouro'):].tolist()\n",
        "    novas_colunas = colunas_antes + ['URL_Valida', 'Telefone'] + colunas_depois\n",
        "\n",
        "    # Reorganiza o DataFrame com as novas colunas\n",
        "    df_urls = df_urls[novas_colunas]\n",
        "\n",
        "    # Solicita o formato de saída\n",
        "    while True:\n",
        "        formato = input(\"Escolha o formato de saída (csv, xlsx ou ods): \").lower().strip()\n",
        "        if formato in ['csv', 'xlsx', 'ods']:\n",
        "            break\n",
        "        print(\"Formato inválido! Escolha entre 'csv', 'xlsx' ou 'ods'.\")\n",
        "\n",
        "    # Define o nome do arquivo de saída com base no formato escolhido\n",
        "    nome_base = os.path.splitext(nome_arquivo)[0]\n",
        "    if formato == 'csv':\n",
        "        arquivo_saida = f\"{nome_base}_com_telefones.csv\"\n",
        "        df_urls.to_csv(arquivo_saida, index=False)\n",
        "        print(f'Arquivo salvo como {arquivo_saida} com {len(df_urls)} entradas.')\n",
        "        files.download(arquivo_saida)\n",
        "        print(f\"Baixe a planilha aqui: {arquivo_saida}\")\n",
        "    elif formato == 'xlsx':\n",
        "        arquivo_saida = f\"{nome_base}_com_telefones.xlsx\"\n",
        "        df_urls.to_excel(arquivo_saida, index=False, engine='openpyxl')\n",
        "        print(f'Arquivo salvo como {arquivo_saida} com {len(df_urls)} entradas.')\n",
        "        files.download(arquivo_saida)\n",
        "        print(f\"Baixe a planilha aqui: {arquivo_saida}\")\n",
        "    elif formato == 'ods':\n",
        "        arquivo_saida = f\"{nome_base}_com_telefones.ods\"\n",
        "        pyexcel_ods3.save_data(arquivo_saida, {'Sheet1': [df_urls.columns.tolist()] + df_urls.values.tolist()})\n",
        "        print(f'Arquivo salvo como {arquivo_saida} com {len(df_urls)} entradas.')\n",
        "        files.download(arquivo_saida)\n",
        "        print(f\"Baixe a planilha aqui: {arquivo_saida}\")\n",
        "\n",
        "# Executa o programa\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "PIqN7YXSFlvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Olá, este é o Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}